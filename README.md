## ml_protein_protein

The objective of this project is to reliably predict the relative binding affinity arising due to mutations in protein structures, which is an active field of research in protein engineering. 

## File Structure

* * * * * * * * * 

* `data`: This directory contains all the data required for training and validation.

* `SKEMPI2_PDBs.tar`: This file contains the cleaned PDB files of the wild type complexes. The data is downloaded from the [SKEMPI v2.0 website](https://life.bsc.es/pid/skempi2/).

* `pdbs_wt/`: This directory contains the PDB files corresponding to the wild type complexes.

* `pdbs_mutated/`: This directory contains the PDB files corresponding to mutants of the complexes in `pdbs_wt/`. The mutants are generated by applying random missense mutations to the SKEMPI complexes.

* `skempi_v2_cleaned.csv`: This CSV file contains information about the PDB complexes in a more readable format.

* `S19.txt, S33.txt, S4191.txt, S487.txt, S877.txt, M1701.txt`: These are some of the notable datasets used for comparing results in the reference papers of MutaBind, iSEE and SKEMPI. Note that S indicates single mutations and M indicates multiple mutations. 

* `features_wt`: This directory contains the features for wild type complexes, as numpy elements, used for training different ML models. 

* `features_mut`: This directory contains the features for the mutant complexes, as numpy elements, used for training different ML models.

* * * * * * * * * 

* `scripts`: This directory contains all the Python scripts used for data acquisition, preprocessing, training and validation. 

* `constants.py`: It contains a list of all the common constant values used by rest of the scripts.

* `pdb_pipeline.py`: It cleans and generates the features required for the models using OpenMM for simulation.

* `preprocessing_mlp.py` : It preprocesses the features generated by `pdb_pipeline.py` and generates a CSV for usage by `mlp.py`.

* `mlp.py`: It implements the MLP model approach.

* `tune_xgboost.py`: It implements the XGBoost model approach.

* `siamese_network.py`: It implements the siamese network (HydraNet) approach.

* `misc_helpers.py`: It contains the functions used for preprocessing the data.

* `utilities.py`: It contains simple utility functions which are used by rest of the scripts.

* `train_helpers.py`: It contains the common functions used for training in the different models.

* * * * * * * * * 

* `notebooks`: It contains the data_exploration.ipynb jupyter notebook which is used for visualising and exploring the dataset for this project. 

* * * * * * * * * 

## Requirements

* Anaconda or [Miniconda](https://docs.conda.io/en/latest/miniconda.html) (latter takes less time to install) as your python distribution.

> **Note**: due to the `pdbfixer` and `openmm` packages, this project is running on Python 3.7.

> **Note**: having an Nvidia GPU available is highly recommended, although not necessary.

## Installation

Install the env with the following command:
```
conda env create -f environment.yml
```

Now activate the conda environment by typing:
```
conda activate ml_protein_protein
```

If you need to update the environment use:
```
conda env update -f environment.yml
```

If for whatever reason you need to delete the environment due to conflicts, you can run:
```
conda env remove -n ml_protein_protein
```

Thereafter you have to run `conda deactivate` and you will be able to reinstall everything properly. 

> A `Makefile` already provides these commands for faster access. Simply run `make install-env`.

If you want to make sure your files are pep8 compliant before committing then create a pre-commit file in .git/hooks/
with the following content:
```
#!/bin/sh
set -e

flake8 --max-line-length=120
```
